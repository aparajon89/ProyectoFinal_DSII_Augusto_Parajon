Proyecto Final â€“ Data Science II

AnÃ¡lisis ClimÃ¡tico Aplicado a la PlanificaciÃ³n Comercial en Retail

ğŸ“Œ DescripciÃ³n

Este proyecto busca anticipar la demanda de productos de climatizaciÃ³n en Oscar Barbieri S.A. mediante el anÃ¡lisis de datos climÃ¡ticos histÃ³ricos de San Miguel de TucumÃ¡n (2005â€“2025) obtenidos desde la API Open-Meteo.

Se utilizÃ³ la metodologÃ­a CRISP-DM, integrando anÃ¡lisis exploratorio, ingenierÃ­a de atributos y modelos de Machine Learning para predecir extremos climÃ¡ticos que impactan en las ventas de calefacciÃ³n y refrigeraciÃ³n.

ğŸ¯ Objetivos

Retomar el trabajo exploratorio previo y sumarle modelos de Machine Learning.

Modelar la situaciÃ³n como un problema de clasificaciÃ³n de extremos climÃ¡ticos.

Entrenar y evaluar distintos algoritmos (Logistic Regression, Random Forest, Gradient Boosting, SVC, XGBoost, KNN).

Aplicar tÃ©cnicas de optimizaciÃ³n de hiperparÃ¡metros.

Seleccionar el modelo con mejor desempeÃ±o segÃºn mÃ©tricas de clasificaciÃ³n.

Traducir los hallazgos en insights aplicables a la planificaciÃ³n comercial y logÃ­stica en retail.

ğŸ—‚ Dataset

Fuente: API Open-Meteo (https://open-meteo.com
).

Periodo: 01/01/2005 â€“ 31/07/2025.

UbicaciÃ³n: San Miguel de TucumÃ¡n, Argentina.

Variables principales: temperaturas mÃ­n/mÃ¡x, temperatura aparente, precipitaciones, viento, humedad, radiaciÃ³n solar.

Target: etiqueta de extremos climÃ¡ticos (olas de calor/frÃ­o).

ğŸ” MetodologÃ­a

AdquisiciÃ³n de datos: descarga desde la API y exportaciÃ³n a CSV.

Wrangling y limpieza: control de nulos, duplicados y plausibilidad de rangos.

EDA: hipÃ³tesis H1â€“H6, estacionalidad, persistencia, percentiles vs. umbrales y clustering multivariado.

IngenierÃ­a de atributos:

Variables temporales (dÃ­a, mes, estaciÃ³n, transformaciones trigonomÃ©tricas).

Flags de extremos.

Persistencia (lags y rolling means).

PCA y clustering como features adicionales.

Modelado y validaciÃ³n: entrenamiento de modelos base y avanzados con TimeSeriesSplit.

OptimizaciÃ³n: GridSearchCV y RandomizedSearchCV.

Interpretabilidad: coeficientes de Logistic Regression y anÃ¡lisis SHAP.

Conclusiones: aplicaciÃ³n a decisiones de inventario, logÃ­stica y campaÃ±as comerciales.

ğŸ“Š Resultados

Mejores modelos: Logistic Regression y Gradient Boosting (segÃºn F1 y ROC-AUC).

Hallazgos clave:

La temperatura aparente supera en predictividad a la temperatura seca.

Percentiles mÃ¡s robustos que umbrales absolutos.

Los clusters muestran perfiles climÃ¡ticos diferenciados.

AplicaciÃ³n en negocio: anticipaciÃ³n de picos de demanda, planificaciÃ³n logÃ­stica y optimizaciÃ³n comercial.

âš™ï¸ Requisitos

Ejecutar en Google Colab o entorno local con Python 3.10+.
LibrerÃ­as principales:

numpy, pandas, matplotlib, seaborn

scikit-learn, xgboost, shap

InstalaciÃ³n rÃ¡pida en Colab:

!pip install numpy pandas scikit-learn xgboost shap seaborn matplotlib --quiet

ğŸš€ EjecuciÃ³n

Clonar el repositorio:

git clone https://github.com/aparajon89/ProyectoFinal_DSII_Augusto_Parajon.git
cd ProyectoFinal_DSII_Augusto_Parajon


Abrir la notebook en Jupyter o Colab:
ProytectoFinal_DSII_Augusto_Parajon.ipynb

Ejecutar todas las celdas con Restart & Run All.

ğŸ“‚ Estructura del repositorio
â”œâ”€â”€ ProytectoFinal_DSII_Augusto_Parajon.ipynb   # Notebook principal
â”œâ”€â”€ clima_tucuman_historico.csv                 # Dataset generado
â””â”€â”€ README.md                                   # Este archivo

ğŸ‘¤ Autor

Augusto ParajÃ³n â€“ Proyecto Final, Data Science II.
